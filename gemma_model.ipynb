{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "648673a6-2be0-49bc-ba74-28adc2741316",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2f0624df3e340afb6d08c1373c1a693",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n",
      "Device set to use cuda\n",
      "/workspace/.venv/lib/python3.11/site-packages/torch/_inductor/compile_fx.py:236: UserWarning: TensorFloat32 tensor cores for float32 matrix multiplication available but not enabled. Consider setting `torch.set_float32_matmul_precision('high')` for better performance.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'input_text': '<start_of_image> in this image, there is', 'generated_text': '<start_of_image> in this image, there is one solitary bee, the exact same size as a penny, collecting nectar from the pink flower'}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "import torch\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"image-text-to-text\",\n",
    "    model=\"google/gemma-3-4b-pt\",\n",
    "    device=\"cuda\",\n",
    "    torch_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "output = pipe(\n",
    "    \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/bee.jpg\",\n",
    "    text=\"<start_of_image> in this image, there is\"\n",
    ")\n",
    "\n",
    "print(output)\n",
    "# [{'input_text': '<start_of_image> in this image, there is',\n",
    "# 'generated_text': '<start_of_image> in this image, there is a bumblebee on a pink flower.\\n\\n'}]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5535d6e7-8d4c-4d9a-8d1f-449ef06b1152",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5541cd450f340a98f8e8bd9b16069f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3d81b2a-0720-4254-8cb3-7e3e8e61958a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'input_text': '<start_of_image> in this image, there is', 'generated_text': '<start_of_image> in this image, there is a bumblebee flying from the top of the picture to the very bottom\\n\\ni went on a field trip to the national botanical garden of singapore on may 3, 2013 with 5 friends and we saw so many amazing flora like bromeliads, epiphytes, carnivorous plants, gingers, bananas and so many more!\\n\\nthis field trip was so fun and i am glad i went! : D\\n\\n'}]\n"
     ]
    }
   ],
   "source": [
    "output = pipe(\n",
    "    \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/bee.jpg\",\n",
    "    text=\"<start_of_image> in this image, there is\"\n",
    ")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "96519538-4eaf-4610-97e1-14aa9d48bcbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'input_text': '<start_of_image> in this image, there is kiosk UI', 'generated_text': '<start_of_image> in this image, there is kiosk UI of Cafe that I made.\\n\\n \\nI made a kiosk application as a part of the graduation project of Digital Media Design Major at Myongji University.\\n\\nThis kiosk is a tablet with kiosk program that customers can see a coffee menu in a cafe, order, pay and collect their drink.\\n\\nIn addition, customers can select additional menu after placing an order and also, customer can use a loyalty card.\\n\\n \\n\\nThanks to \"VUE.js\" and \"Vuex\" libraries,\\n\\nI was able to build a kiosk application with complex logics in a simple way.\\n\\nand in addition, I can access kiosk database easily.\\n\\n \\nThere are some things to fix or improve in this project, but this project is a proud work for me because it is my first work after graduated from university!\\n\\n'}]\n"
     ]
    }
   ],
   "source": [
    "output = pipe(\n",
    "    \"coffee-000713f3-screen.jpg\",\n",
    "    text=\"<start_of_image> in this image, there is kiosk UI\"\n",
    ")\n",
    "print(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
